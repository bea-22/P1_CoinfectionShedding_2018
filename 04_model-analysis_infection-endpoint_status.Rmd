---
title: "03_model-analysis_infection-endpoint_status"
author: "Bryony Allen"
date: "16/02/2018"
output:
  pdf_document:
    toc: false 
    number_sections: true
    fig_caption: yes
    keep_tex: yes
---
# NOTES & SOURCES #
 
I use ExperimentNo as a proxy for species
where "1" = "Bufo bufo I", "2" = "Bufo bufo II", "3" = "Rana temporaria", "4" = "Alytes muletensis"

https://bookdown.org/ndphillips/YaRrr/linear-regression-with-lm.html 


# QUESTIONS #

? should I look at the Pearson residuals ? 
  Pearson residual is the raw residual divided by the square root of the variance function. To account for the mean variance relationship...shows whether particular observations affect estimation and results 

https://data.princeton.edu/wws509/notes/c3s8 

# Install & load in required packages 

```{r packages, include=FALSE, warning=FALSE, error=FALSE, message=FALSE}
# for tidying data  
library(dplyr)
# library(tidyr)
# library(tibble)

# for plotting 
library(ggplot2) 
library(lattice)

# for stats 
library(binom)
# library(purr)  # purr guidance > for evaluating models http://ijlyttle.github.io/isugg_purrr/presentation.html#(1) 
# library(broom)   # broom summarizes key information about models in tidy tibble()s >> https://github.com/tidymodels/broom
```

# Part 1: Import data 

> At the moment this code chuck reads in a .csv file with endpoint infection data, originally compiled in excel and then cleaned in "02_tidy_data-qpcr"script. In the future you will read in the .csv file of merged qPCR outputs (created, checked and cleaned in "02_tidy_data-qpcr"script) and experiment metadata (checked and cleaned in "02_tidy_data-metadata"script). 

```{r import data, include=FALSE, warning=FALSE, error=FALSE, message=FALSE}

data.endpoint <- read.csv('data/02_clean-data.csv') 

glimpse(data.endpoint)   # check how the dataset has imported (aka whether it has the data type right)  
    data.endpoint$ExperimentNo <-  as.factor(data.endpoint$ExperimentNo)   # convert $ExperimentNo. to factor 
```

# Part 2: Endpoint Infection Status

Binomial GLM's where 
  response variable = Endpoint status [binary; 0,1] 
  explanatory variable(s) = Treatment  [categorical]   &   Species [categorical]

## Part 2a: Endpoint Infection Status: **Bd** 

Here I have removed the Rv-only treatment group as they have never been exposued to Bd << ? could use them as a control group? I also removed the Am5 (baby Alytes) as they only have one treatment group which I will analyse seperately.   

```{r Bd status df, echo=FALSE}
Bd.status <- data.endpoint %>%
  filter(!Treatment=="Rv") %>%
  filter(!ExperimentNo=='5')  %>% 
  mutate(ExperimentNo = as.factor(ExperimentNo)) %>% 
  select(ID, Species, ExperimentNo, Scenario, Treatment, Bd.endpoint.status, Bd.endpoint.GE) 

droplevels(Bd.status)
```

### Maximal Model: Species*Treamtent interaction 
Fit the most complex model first (maximal model). 

Look at the estimates of the coefficients using ```summary()```
```{r Bd binomial glm}
Bd.status1 <- glm(Bd.endpoint.status ~ Treatment * ExperimentNo, data=Bd.status, family=binomial)
summary(Bd.status1)
```

```{r Bd binomial glm plot, fig.cap= "Diagnostic plots for GLM looking at Bd endpoint infection status by Treamtent group and Species with interactions"}
par(mfrow=c(2,2), mar=c(3,3,3,1), mgp=c(2,0.8,0))
plot(Bd.status1)
```
The diagnostic plots in Figure \@ref(fig:Bd binomial glm plot) aren't ideal 
- residual vs. fitted shows patterning meaning the variance is non-consistent
- residual vs. leverage also shows patterning suggesting certain data points have strong influence  

### Simplification Model 1: Species + Treamtent  
Now fit a simpler model has an with only the main effects for Species and Treatment 
```{r binomial glm 2}
Bd.status2 <- glm(Bd.endpoint.status ~ Treatment + ExperimentNo, data=Bd.status, family=binomial)
summary(Bd.status2)
```

```{r binomial glm plot 2, fig.cap= "Diagnostic plots for GLM looking at Bd endpoint infection status by Treamtent group and Species (no interaction)"}
par(mfrow=c(2,2), mar=c(3,3,3,1), mgp=c(2,0.8,0))
plot(Bd.status2)
```

### Model Comparison: ANOVA 

Analysis of deviance with ```test='Chi'``` selected because of the binomial error family 
... "an ANOVA testing whether the more complex model is significantly better at capturing the data than the simpler model. If the resulting p-value is sufficiently low (usually less than 0.05), we conclude that the more complex model is significantly better than the simpler model, and thus favor the more complex model. If the p-value is not sufficiently low (usually greater than 0.05), we should favor the simpler model."

```{r binomial glm anova}
Bd.status1 <- glm(Bd.endpoint.status ~ Treatment * ExperimentNo, data=Bd.status, family=binomial)
Bd.status2 <- glm(Bd.endpoint.status ~ Treatment + ExperimentNo, data=Bd.status, family=binomial)
Bd.status3 <- glm(Bd.endpoint.status ~ Treatment, data=Bd.status, family=binomial)
Bd.status4 <- glm(Bd.endpoint.status ~ ExperimentNo, data=Bd.status, family=binomial)

# compare the simplest models first 
anova(Bd.status2, Bd.status4, test="Chisq") # compares Trt and Sp to just Sp 
anova(Bd.status2, Bd.status3, test="Chisq") # compares Trt and Sp to just Trt 
# compare more complex model to one with interaction 
anova(Bd.status1, Bd.status2, test="Chisq")

```
ANOVA 1: suggests we should reject the more complex model (Treatment + ExperimentNo) in favour for just the model with ExperimentNo only  (pvalue = 0.48)
ANOVA 2: suggests we should favour the more complex model (Treatment + ExperimentNo) over the model with Treatment only  (pvalue = < .001)  as adding ExperimentNo did lead to significantly improved fit 
ANOVA 1: shows adding a interaction term between Treatment and ExperimentNo did not significantly imporve fit (p-value = 0.5752)

### Model Fit:   
To see the fitted values from a regression object (the values of the dependent variable predicted by the model), access the ```fitted.values``` attribute from a regression object with ````$fitted.values```.

```{r fitted values}
names(Bd.status2)   # look at the components of the glm object

Bd.status$bi.glm <- Bd.status2$fitted.values  # add logisitic fitted values back to the dataframe as a new col

head(Bd.status)   # look at the components of the glm object

```

### Model Plotting:   
To plot the model you need a range of values for which to produce fitted values. Then use the ```predict()``` function to create the model for all the values. ```predict()``` gives you the predicted values based on your (fitted) linear model, the argument type="response" will give you the predicted probabilities 

**N.B** the code isn't working here (09.04.19) 

```{r plot - bi.glm - species and treatment}
Bd.status2 <- glm(Bd.endpoint.status ~ Treatment + ExperimentNo, data=Bd.status, family=binomial)

# create a dataframe of "new" data 
newdat <- expand.grid(ExperimentNo=c("1", "2", "3", "4"),Treatment=c("Bd", "Bd-Rv", "Rv-Bd"))

# predict the value/result of the new data using the glm
newdat <-cbind(newdat, predict(object = Bd.status2,   # the model 
                               newdata=newdat, se=TRUE, type="response", print.matrix=T))  # dataframe of new data 
newdat

expl.var <- c(1:3) # chose the range for the x-axis (Experiment No.)
exp.labs <- c("1" = "Bufo bufo I", "2" = "Bufo bufo II", "3" = "Rana temporaria", "4" = "Alytes muletensis")

newdat1<- subset(newdat, ExperimentNo== "1")    # need to subset the data so you can plot each seperatly 
newdat2<- subset(newdat, ExperimentNo=="2")
newdat3<- subset(newdat, ExperimentNo=="3")
newdat4<- subset(newdat, ExperimentNo=="4")

Bd.status.predict <- ggplot(newdat, aes(x= expl.var, y= fit, color=ExperimentNo)) +       # plot model estimates, color= the data you subsetted by
  geom_line(data = newdat1, aes(x= expl.var, y= fit), size=1) +                                   # add lines for subset newdat1
  geom_errorbar(data = newdat1, aes(ymin=fit-se.fit, ymax=fit+se.fit), width=.03, size=1)  +      # error bars for subset newdat1
  geom_line(data = newdat2, aes(x= expl.var, y= fit), size=1) +                                   # add lines for subset newdat2
  geom_errorbar(data = newdat2, aes(ymin=fit-se.fit, ymax=fit+se.fit), width=.03, size=1)  +      # error bars for subset newdat2
  geom_line(data = newdat3, aes(x= expl.var, y= fit), size=1) +                                   # add lines for subset newdat1
  geom_errorbar(data = newdat3, aes(ymin=fit-se.fit, ymax=fit+se.fit), width=.03, size=1)  +      # error bars for subset newdat1
  geom_line(data = newdat4, aes(x= expl.var, y= fit), size=1) +                                   # add lines for subset newdat1
  geom_errorbar(data = newdat4, aes(ymin=fit-se.fit, ymax=fit+se.fit), width=.03, size=1) +       # error bars for subset newdat1
    scale_x_continuous(breaks=seq(1:3),labels=c("Bd", "Bd-Rv", "Rv-Bd"))    # sets the breaks at 1,2 and 3 which correspond to the label names
      
Bd.status.predict.plot <- Bd.status.predict + 
  ylab("Bd status predictions\n(fit)") +            # TO DO: would be good to have the axis marking 0 & 1 
  xlab("Treatment Group") +
  ggtitle("Probability of Bd infection predicted by\n glm(Bd.endpoint.status ~ Treatment + ExperimentNo, 
    family = binomial)") +
  #guides(fill=guide_legend(title="Species")) +      # TO DO: fix the labelling issues here 
  #scale_fill_discrete(labels=exp.labs) +
  theme_bw() +
  theme(panel.border = element_blank(), panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) 

# export plot as .png 
png("figs/04_model-analysis_infection-end-status.png", type="cairo", units="in", width= 14, height=8, pointsize= 12, res=1000)
print(Bd.status.predict.plot)
dev.off()

```

### Models Checks 

```{r}
summary(Bd.status2)  # AIC: 118.76
summary(Bd.status4)  # AIC: 116.19

plot(Bd.status4)

influence.measures(Bd.status4) # table displaying the influence measures of each point  
```

## Part 2a: Endpoint Infection Status: **Ranavirus** 

Here I have removed the Bd-only treatment group as they have never been exposued to Ranavirus

```{r Rv status df, echo=FALSE}
Rv.status <- data.endpoint %>%
  filter(!Treatment=="Bd") %>%
  filter(!ExperimentNo=='5')  %>% 
  mutate(ExperimentNo = as.factor(ExperimentNo)) %>% 
  select(ID, Species, ExperimentNo, Scenario, Treatment, Rv.MCPendpoint.status, Rv.endpoint.load) 

droplevels(Rv.status)

glimpse(Rv.status)
```

### Model Comparison: ANOVA 

Analysis of deviance with ```test='Chi'``` selected because of the binomial error family 
... "an ANOVA testing whether the more complex model is significantly better at capturing the data than the simpler model. If the resulting p-value is sufficiently low (usually less than 0.05), we conclude that the more complex model is significantly better than the simpler model, and thus favor the more complex model. If the p-value is not sufficiently low (usually greater than 0.05), we should favor the simpler model."

```{r binomial glm anova}
Rv.status1 <- glm(Rv.MCPendpoint.status ~ Treatment * ExperimentNo, data=Rv.status, family=binomial)
Rv.status2 <- glm(Rv.MCPendpoint.status ~ Treatment + ExperimentNo, data=Rv.status, family=binomial)
Rv.status3 <- glm(Rv.MCPendpoint.status ~ Treatment, data=Rv.status, family=binomial)
Rv.status4 <- glm(Rv.MCPendpoint.status ~ ExperimentNo, data=Rv.status, family=binomial)

# compare the simplest models first 
anova(Rv.status2, Rv.status4, test="Chisq") # compares Trt and Sp to just Sp 
anova(Rv.status2, Rv.status3, test="Chisq") # compares Trt and Sp to just Trt 
# compare more complex model to one with interaction 
anova(Rv.status1, Rv.status2, test="Chisq")

```
ANOVA 1: suggests we should favour the more complex model (Treatment + ExperimentNo) in favour for just the model with ExperimentNo only  (pvalue = < .001)  adding Treatment did lead to significantly improved fit 
ANOVA 2: suggests we should reject the more complex model (Treatment + ExperimentNo) over the model with Treatment only  (pvalue = 0.07962) 
ANOVA 1: shows adding a interaction term between Treatment and ExperimentNo did not significantly imporve fit (p-value = 0.4642)

### Model Fit:   
To see the fitted values from a regression object (the values of the dependent variable predicted by the model), access the ```fitted.values``` attribute from a regression object with ````$fitted.values```.

```{r fitted values}
Rv.status$bi.glm <- Rv.status2$fitted.values  # add logisitic fitted values back to the dataframe as a new col
head(Rv.status)   # look at the components of the glm object
```
It looks like the model is struggling to predict the probability of infection status accurately. 

### Model Plotting:   
To plot the model you need a range of values for which to produce fitted values. Then use the ```predict()``` function to create the model for all the values. ```predict()``` gives you the predicted values based on your (fitted) linear model, the argument type="response" will give you the predicted probabilities 


```{r plot - bi.glm - species and treatment}
Rv.status2 <- glm(Rv.MCPendpoint.status ~ Treatment + ExperimentNo, data=Rv.status, family=binomial)

str(Rv.status)

# create a dataframe of "new" data 
Rv.newdat <- expand.grid(ExperimentNo=c("1", "2", "3", "4"),Treatment=c("Bd-Rv", "Rv", "Rv-Bd"))

# predict the value/result of the new data using the glm
Rv.newdat <-cbind(Rv.newdat, predict(object = Rv.status2,   # the model 
                               newdata=Rv.newdat, se=TRUE, type="response", print.matrix=T))  # dataframe of new data 
Rv.newdat

expl.var <- c(1:3) # chose the range for the x-axis (Treatment)
# exp.labs <- c("1" = "Bufo bufo I", "2" = "Bufo bufo II", "3" = "Rana temporaria", "4" = "Alytes muletensis")

newdat1<- subset(Rv.newdat, ExperimentNo== "1")    # need to subset the data so you can plot each seperatly 
newdat2<- subset(Rv.newdat, ExperimentNo=="2")
newdat3<- subset(Rv.newdat, ExperimentNo=="3")
newdat4<- subset(Rv.newdat, ExperimentNo=="4")

Rv.status.predict <- ggplot(Rv.newdat, aes(x= expl.var, y= fit, color=ExperimentNo)) +       # plot model estimates, color= the data you subsetted by
  geom_line(data = newdat1, aes(x= expl.var, y= fit), size=1) +                                   # add lines for subset newdat1
  geom_errorbar(data = newdat1, aes(ymin=fit-se.fit, ymax=fit+se.fit), width=.03, size=1)  +      # error bars for subset newdat1
  geom_line(data = newdat2, aes(x= expl.var, y= fit), size=1) +                                   # add lines for subset newdat2
  geom_errorbar(data = newdat2, aes(ymin=fit-se.fit, ymax=fit+se.fit), width=.03, size=1)  +      # error bars for subset newdat2
  geom_line(data = newdat3, aes(x= expl.var, y= fit), size=1) +                                   # add lines for subset newdat1
  geom_errorbar(data = newdat3, aes(ymin=fit-se.fit, ymax=fit+se.fit), width=.03, size=1)  +      # error bars for subset newdat1
  geom_line(data = newdat4, aes(x= expl.var, y= fit), size=1) +                                   # add lines for subset newdat1
  geom_errorbar(data = newdat4, aes(ymin=fit-se.fit, ymax=fit+se.fit), width=.03, size=1) +       # error bars for subset newdat1
    scale_x_continuous(breaks=seq(1:3),labels=c("Bd-Rv", "Rv", "Rv-Bd"))    # sets the breaks at 1,2 and 3 which correspond to the label names
      
Rv.status.predict.plot <- Rv.status.predict + 
  ylab("Rv status predictions\n(fit)") +            # TO DO: would be good to have the axis marking 0 & 1 
  xlab("Treatment Group") +
  ggtitle("Probability of Ranavirus infection predicted by\n glm(Bd.endpoint.status ~ Treatment + ExperimentNo, 
    family = binomial)") +
  #guides(fill=guide_legend(title="Species")) +      # TO DO: fix the labelling issues here 
  #scale_fill_discrete(labels=exp.labs) +
  theme_bw() +
  theme(panel.border = element_blank(), panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) 

# export plot as .png 
png("figs/04_model-analysis_infection-end-status_Rv.png", type="cairo", units="in", width= 14, height=8, pointsize= 12, res=1000)
print(Rv.status.predict.plot)
dev.off()

```

### Models Checks 

```{r}
summary(Rv.status2)  # AIC: 151.25
summary(Rv.status3)  # AIC: 152.02

plot(Bd.status4)

influence.measures(Bd.status4) # table displaying the influence measures of each point  
```


################### SCRAPS ################### SCRAPS ################### SCRAPS ################### SCRAPS ################### SCRAPS ################### SCRAPS ################### SCRAPS ###################


data.endpoint %>% 
   filter((Bd.endpoint.status=='1' & Bd.endpoint.GE > 0.1))  %>% 
     do(model = lm(Bd.endpoint.GE ~ Species + Treatment, data = .))

mod.Bd.status.bi <- data.endpoint %>%
  filter(!Treatment== "Rv") %>% do(model = glm(Bd.endpoint.status ~ Treatment * ExperimentNo, data=., family=binomial)) 
  
```{r do models worked example}
by_cyl <- group_by(mtcars, cyl)
do(by_cyl, head(., 2))
models <- by_cyl %>% do(mod = lm(mpg ~ disp, data = .))
models

summarise(models, rsq = summary(mod)$r.squared)
models %>% do(data.frame(coef = coef(.$mod)))
models %>% do(data.frame(
  var = names(coef(.$mod)),
  coef(summary(.$mod)))
)

```
